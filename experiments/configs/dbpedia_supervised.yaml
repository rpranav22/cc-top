model_params:
    model: 'supervised_plm'
    loss: None
    architecture:
        arch: bert_classifier
        base_model: 'bert-base-uncased'
        num_classes: 14
        

exp_params:
    dataset: 'dbpedia'
    val_size: 20000
    true_num_classes: 14
    batch_size: 256
    max_length: 64
    is_tensor: True
    constraintmatch: False
    constrained_clustering: False
    num_workers: 0
    pin_memory: False
    learning_rate: 0.00002
    adam_epsilon: 0.00000001
    weight_decay: 0.01
    warmup_steps: 0
    num_constraints: 10000
    clean_text: False
    remove_stopwords: False
    k: NULL
    
trainer_params:
    max_epochs: 3
    min_epochs: 1
    

logging_params:
    manual_seed: 1337
    experiment_name: 'supervised_plm'
    run_name: 'dbpedia_lr2'
