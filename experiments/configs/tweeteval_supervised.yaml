model_params:
    model: 'supervised_plm'
    loss: None
    architecture:
        arch: bert_classifier
        base_model: 'bert-base-uncased'
        num_classes: 20
        

exp_params:
    dataset: 'tweeteval'
    val_size: 0.5
    true_num_classes: 20
    batch_size: 64
    max_length: 32
    is_tensor: True
    constraintmatch: False
    constrained_clustering: False
    num_workers: 0
    pin_memory: False
    learning_rate: 0.00001
    adam_epsilon: 0.00000001
    weight_decay: 0.01
    warmup_steps: 0
    num_constraints: 20000
    clean_text: False
    remove_stopwords: False
    k: NULL
    
trainer_params:
    max_epochs: 20
    min_epochs: 1
    

logging_params:
    manual_seed: 1337
    experiment_name: 'supervised_plm'
    run_name: 'tweeteval_supervised'
