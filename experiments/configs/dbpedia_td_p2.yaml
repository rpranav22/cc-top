model_params:
    model: 'constrained_clustering'
    loss: KCL
    model_uri: 'mlruns/22/8206093eeadd48b6b35e58f22ad3c525/artifacts/final_model.pt'
    architecture:
        arch: bert_classifier
        base_model: 'bert-base-uncased'
        num_classes: 100

exp_params:
    dataset: 'dbpedia'
    true_num_classes: 14
    val_size: 0.5
    batch_size: 256
    max_length: 64
    num_constraints: 5000
    new_samples: 9000
    constrained_clustering: True
    topic_discovery: True
    train_type: 'finetune'
    test_set: 'combined'
    new_split: '2v2'
    phase: 2
    excluded_classes: [0,1,2,3,4,5,6,7,8,9]
    num_workers: 0
    pin_memory: False
    learning_rate: 0.00001
    adam_epsilon: 0.00000001
    weight_decay: 0.0001
    warmup_steps: 0
    clean_text: False
    remove_stopwords: False
    k: NULL
    
trainer_params:
    max_epochs: 300
    min_epochs: 1
    

logging_params:
    manual_seed: 1337
    experiment_name: 'table5_phase-2'
    run_name: 'kcl_finetune_5k_2v2'